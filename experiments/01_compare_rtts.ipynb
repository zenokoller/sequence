{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares the following two methods of getting RTT samples:\n",
    "\n",
    "1. RTTs from TCP timestamps using the method described in \"[New Methods for Passive Estimation of TCP Round-Trip Times](http://cobweb.cs.uga.edu/~kangli/src/pam05.pdf)\"\n",
    "2. RTTs from square waves as described in the [Proposal for adding a Spin Bit to QUIC](https://britram.github.io/draft-trammell-quic-spin/draft-trammell-quic-spin.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_PATH = '/tmp/anon-v4.hdf5' # Path to datapoints from `00_extract_flows.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from collections import namedtuple\n",
    "from typing import Tuple, Callable, NamedTuple, Iterable\n",
    "from itertools import chain\n",
    "from functools import reduce\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from rtt import rtts_from_timestamps, rtts_from_square_wave, Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(STORE_PATH) as store:\n",
    "    tcp_df = store['tcp_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by flows and compute RTTs\n",
    "def compute_rtts(rtt_fn: Callable[[Tuple[str, pd.DataFrame]], pd.DataFrame]) -> pd.DataFrame:\n",
    "    rtt_df = pd.DataFrame()\n",
    "    for flow in tcp_df.groupby('flow_hash'):\n",
    "        rtt_df = pd.concat([rtt_df, rtt_fn(flow)])\n",
    "    return rtt_df\n",
    "\n",
    "tcp_df.set_index(['flow_hash', 'timestamp'])\n",
    "ts_rtt_df = compute_rtts(rtts_from_timestamps)\n",
    "sw_rtt_df = compute_rtts(rtts_from_square_wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, convert the timedeltas to microsecond ints\n",
    "def convert_rtts_to_microseconds(rtt_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rtt_df['rtt'] = rtt_df['rtt'] / np.timedelta64(1, 'us')\n",
    "\n",
    "convert_rtts_to_microseconds(ts_rtt_df)\n",
    "convert_rtts_to_microseconds(sw_rtt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric(NamedTuple):\n",
    "    df: pd.DataFrame\n",
    "    name: str\n",
    "    bits_per_packet: float\n",
    "    sample_rate: float = 1.0\n",
    "        \n",
    "def sample_metric(metric: Metric, sample_rate: float) -> Metric:\n",
    "    \"\"\"Subsamples the metric's `df` with `sample_rate` and recomputes `bits_per_packet`.\"\"\"\n",
    "    assert metric.sample_rate == 1.0, 'Metric has been sampled before!'\n",
    "    sampled_df = metric.df.sample(frac=sample_rate)\n",
    "    bits_per_packet= len(sampled_df) * metric.bits_per_packet / len(metric.df)\n",
    "    return Metric(df=sampled_df,\n",
    "                     name=metric.name, \n",
    "                     sample_rate=sample_rate, \n",
    "                     bits_per_packet=bits_per_packet)\n",
    "\n",
    "SAMPLE_RATES = [0.25,0.5,1]\n",
    "\n",
    "TIMESTAMP_HEADER_SIZE = 64.0  # bits\n",
    "ts_metric = Metric(df=ts_rtt_df, name='Timestamp RTT', bits_per_packet=TIMESTAMP_HEADER_SIZE)\n",
    "\n",
    "sampled_ts_metrics = [sample_metric(ts_metric, rate) for rate in SAMPLE_RATES]\n",
    "sw_metric = Metric(df=sw_rtt_df, name='Square Wave RTT', bits_per_packet=1.0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: This assumes that the RTTs are normally distributed. They are, however, HEAVY-tailed. How to do stats?\n",
    "def aggregate_metric(metric: Metric) -> Metric:\n",
    "    return metric._replace(df=metric.df.groupby('flow_hash').agg({\n",
    "           'rtt': ['mean', 'std', 'count']\n",
    "    }))\n",
    "\n",
    "aggregated_metrics = [aggregate_metric(df) for df in [sw_metric, *sampled_ts_metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def merge_metrics(metrics: Iterable[Metric]) -> pd.DataFrame:\n",
    "    for index, metric in enumerate(metrics):\n",
    "        metric.df.rename({'rtt': f'rtt_{index}'}, axis='columns', inplace=True)\n",
    "    metrics_dfs = (m.df for m in metrics)\n",
    "    return reduce(lambda left, right: left.join(right), metrics_dfs)\n",
    "\n",
    "merge_metrics(aggregated_metrics)\n",
    "\n",
    "def draw_metrics_bar_chart(metrics: Iterable[Metric], unit: str = 'ms'):\n",
    "    df = merge_metrics(metrics)\n",
    "    mean_cols = [(f'rtt_{index}', 'mean') for index in range(len(metrics))]\n",
    "    std_cols = [(f'rtt_{index}', 'std') for index in range(len(metrics))]\n",
    "    \n",
    "    ax = df[mean_cols].plot(kind='bar',\n",
    "                          figsize=(15, 10),\n",
    "                          yerr=df[std_cols].values.T,\n",
    "                          legend=True,\n",
    "                          fontsize=14)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_ylabel(unit)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, \n",
    "              [f'{m.name}, b/p: {int(m.bits_per_packet)}' for m in metrics], \n",
    "              fontsize=14)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "draw_metrics_bar_chart(aggregated_metrics)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
